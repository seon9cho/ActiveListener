# -*- coding: utf-8 -*-
"""QR dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WogcDH0xjk6VVKjdS0jkhKD6ZVkf3DX_
"""

!pip3 install transformers
!pip3 install sentencepiece

import pandas as pd
import json 
import os
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn
from transformers import T5Config, T5Model
from transformers import T5Tokenizer,T5ForConditionalGeneration
import time


from google.colab import drive 
drive.mount('/content/drive',force_remount=True)

pth= "/content/drive/MyDrive/data"
#for filename in os.listdir(pth):
  #print(filename)

class TaskMaster_response(Dataset):

  def __init__(self, dataset_folder):
    self.lst_query=[]
    self.lst_response=[]
    dataset = pd.DataFrame(columns=['index','speaker', 'text', "intent"])
    pth= "/content/drive/MyDrive/data"
    for filename in os.listdir(dataset_folder):
    
      if not ".json" in filename:
        continue


      with open(pth + "/"+filename) as json_file:
        data = json.load(json_file)
                              
        for i in data:
          utter=i[ "utterances"]
          for j in range(len(utter)):
            #print(list(utter[j].values()))
            index= list(utter[j].values())[0]
            speaker = list(utter[j].values())[1]
            text = list(utter[j].values())[2]
            #row = {'index': index, 'speaker': speaker, 'text':text}
            #dataset = dataset.append(row, ignore_index=True)
            if speaker=="USER" or speaker=="user":
                self.lst_query.append(text)
            if speaker=="ASSISTANT" or speaker=="assistant":
                self.lst_response.append(text)
    #print(self.lst_query[:10])
    #print(self.lst_response[:10])
    
    self.parsed_response=[]
    self.parsed_query=[]
    tokenizer = T5Tokenizer.from_pretrained('t5-small')
    model = T5Model.from_pretrained('t5-small')
    print("here1")
    for query in self.lst_query:
        input_ids = tokenizer(query,return_tensors="pt").input_ids
        query = tokenizer.encode(query,return_tensors="pt", max_length=512, truncation=True)
        self.parsed_query.append(query)  

    print("here2")
    for response in self.lst_response:
        input_ids = tokenizer(response,return_tensors="pt").input_ids
        response = tokenizer.encode(response,return_tensors="pt", max_length=512, truncation=True)
        #parsed_response.append((input_ids, response))  
        self.parsed_response.append(response)  
        print("here3")                 

    print("done")
        
        
        
  def __len__(self):
        return len(self.parsed_response)

  def __getitem__(self, idx):
        encoded_response = self.parsed_response[idx]
        encoded_query = self.parsed_query[idx]
        return encoded_query , encoded_response


